{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2SeqImplementation__Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNSZXNkkOkO"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data this way only: \n",
        "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
        "    \n",
        "3. Implement a simple Encoder and Decoder architecture  \n",
        "\n",
        "4.  BLEU score as metric to evaluate your model.\n",
        "\n",
        "5. Use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fU80Ao-AGaob",
        "outputId": "7d78a69c-3fc9-476b-86df-4d4e8c2296ea"
      },
      "source": [
        "!wget http://www.manythings.org/anki/ita-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-24 19:51:40--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3030::6815:5c2c, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7757958 (7.4M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   7.40M  40.3MB/s    in 0.2s    \n",
            "\n",
            "2022-01-24 19:51:41 (40.3 MB/s) - ‘ita-eng.zip’ saved [7757958/7757958]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BCj1KriwtYFs",
        "outputId": "7e6ad15a-5235-47da-fb83-57bfef4334c5"
      },
      "source": [
        "!unzip ita-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9QqElB_nKZos",
        "outputId": "d308d210-c05e-4d70-8e78-e015a3d596dc"
      },
      "source": [
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-24 19:52:10--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
            "--2022-01-24 19:52:10--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc20ceb1fdda04cf0b28c6f4b3b0.dl.dropboxusercontent.com/cd/0/inline/Bea7Lw19yPlapn-6NTbzouZB8yDNROdQiPpVIRYwI4bs-QD1m2xRh-rxY37MmZKdptn7kCoGpln5fAlSqIx2YLptp8UzSCRoGPa_IqkRMnxcceYUnG_6OTxicgB0zq52yPi2FvSXmWFiSUlvGgtKYa5d/file# [following]\n",
            "--2022-01-24 19:52:10--  https://uc20ceb1fdda04cf0b28c6f4b3b0.dl.dropboxusercontent.com/cd/0/inline/Bea7Lw19yPlapn-6NTbzouZB8yDNROdQiPpVIRYwI4bs-QD1m2xRh-rxY37MmZKdptn7kCoGpln5fAlSqIx2YLptp8UzSCRoGPa_IqkRMnxcceYUnG_6OTxicgB0zq52yPi2FvSXmWFiSUlvGgtKYa5d/file\n",
            "Resolving uc20ceb1fdda04cf0b28c6f4b3b0.dl.dropboxusercontent.com (uc20ceb1fdda04cf0b28c6f4b3b0.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uc20ceb1fdda04cf0b28c6f4b3b0.dl.dropboxusercontent.com (uc20ceb1fdda04cf0b28c6f4b3b0.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘glove.6B.100d.txt’\n",
            "\n",
            "glove.6B.100d.txt   100%[===================>] 331.04M  69.1MB/s    in 4.8s    \n",
            "\n",
            "2022-01-24 19:52:16 (69.0 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXdcVHle9XpA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau,EarlyStopping\n",
        "import nltk.translate.bleu_score as bleu\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from nltk.translate import bleu_score"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "YvfwFa7c9iQq",
        "outputId": "b921d380-bcc5-4b15-fc90-60aa694fbaec"
      },
      "source": [
        "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])\n",
        "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(353281, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9680cb6f-17ff-4d62-ac21-3b5d3846c026\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9680cb6f-17ff-4d62-ac21-3b5d3846c026')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9680cb6f-17ff-4d62-ac21-3b5d3846c026 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9680cb6f-17ff-4d62-ac21-3b5d3846c026');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1     Hi.     Ciao.\n",
              "2    Run!    Corri!\n",
              "3    Run!    Corra!\n",
              "4    Run!  Correte!"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sH4Tfl3g9lRB",
        "outputId": "953392fc-b947-4e09-cbd5-2173af1cc9ac"
      },
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # I have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['english'] = data['english'].apply(preprocess)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f380443a-4661-4225-a21c-f531421435e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f380443a-4661-4225-a21c-f531421435e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f380443a-4661-4225-a21c-f531421435e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f380443a-4661-4225-a21c-f531421435e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "ESNcDx9f914L",
        "outputId": "8621450f-98b9-45ac-b455-6174ea214630"
      },
      "source": [
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 20]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 20]\n",
        "\n",
        "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
        "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
        "\n",
        "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-783549d3-f9b3-4f63-a372-bafb4e7ab4a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-783549d3-f9b3-4f63-a372-bafb4e7ab4a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-783549d3-f9b3-4f63-a372-bafb4e7ab4a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-783549d3-f9b3-4f63-a372-bafb4e7ab4a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   italian  english_inp english_out\n",
              "0     ciao   <start> hi    hi <end>\n",
              "1     ciao   <start> hi    hi <end>\n",
              "2    corri  <start> run   run <end>\n",
              "3    corra  <start> run   run <end>\n",
              "4  correte  <start> run   run <end>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "yxouecbE93RR",
        "outputId": "cbe788c6-8495-4383-f9e7-3a0e1130169a"
      },
      "source": [
        "data.sample(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-93766755-13b7-42b1-ab13-a4488e15e135\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>289143</th>\n",
              "      <td>non è facile parlare bene in francese</td>\n",
              "      <td>&lt;start&gt; it is not easy to speak french well</td>\n",
              "      <td>it is not easy to speak french well &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352481</th>\n",
              "      <td>linsegnante ha affermato che ci avrebbe fatto ...</td>\n",
              "      <td>&lt;start&gt; the teacher claimed that he would have...</td>\n",
              "      <td>the teacher claimed that he would have us all ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94461</th>\n",
              "      <td>i ragazzi hanno sete</td>\n",
              "      <td>&lt;start&gt; the boys are thirsty</td>\n",
              "      <td>the boys are thirsty &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21748</th>\n",
              "      <td>le due si sono baciate</td>\n",
              "      <td>&lt;start&gt; the two kissed</td>\n",
              "      <td>the two kissed &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349746</th>\n",
              "      <td>che tipo di birra vuoi coshai alla spina</td>\n",
              "      <td>&lt;start&gt; what kind of beer do you want what do ...</td>\n",
              "      <td>what kind of beer do you want what do you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106694</th>\n",
              "      <td>io mi prenderò cura di te</td>\n",
              "      <td>&lt;start&gt; i will take care of you</td>\n",
              "      <td>i will take care of you &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174771</th>\n",
              "      <td>tom è un battitore molto bravo</td>\n",
              "      <td>&lt;start&gt; tom is a very good batter</td>\n",
              "      <td>tom is a very good batter &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79958</th>\n",
              "      <td>anche loro mi hanno aiutato</td>\n",
              "      <td>&lt;start&gt; they helped me too</td>\n",
              "      <td>they helped me too &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77325</th>\n",
              "      <td>sto cercando delle risposte</td>\n",
              "      <td>&lt;start&gt; i am seeking answers</td>\n",
              "      <td>i am seeking answers &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112028</th>\n",
              "      <td>a tom serve un ombrello</td>\n",
              "      <td>&lt;start&gt; tom needs an umbrella</td>\n",
              "      <td>tom needs an umbrella &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93766755-13b7-42b1-ab13-a4488e15e135')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93766755-13b7-42b1-ab13-a4488e15e135 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93766755-13b7-42b1-ab13-a4488e15e135');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  italian  ...                                        english_out\n",
              "289143              non è facile parlare bene in francese  ...          it is not easy to speak french well <end>\n",
              "352481  linsegnante ha affermato che ci avrebbe fatto ...  ...  the teacher claimed that he would have us all ...\n",
              "94461                                i ragazzi hanno sete  ...                         the boys are thirsty <end>\n",
              "21748                              le due si sono baciate  ...                               the two kissed <end>\n",
              "349746           che tipo di birra vuoi coshai alla spina  ...  what kind of beer do you want what do you have...\n",
              "106694                          io mi prenderò cura di te  ...                      i will take care of you <end>\n",
              "174771                     tom è un battitore molto bravo  ...                    tom is a very good batter <end>\n",
              "79958                         anche loro mi hanno aiutato  ...                           they helped me too <end>\n",
              "77325                         sto cercando delle risposte  ...                         i am seeking answers <end>\n",
              "112028                            a tom serve un ombrello  ...                        tom needs an umbrella <end>\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJSPYiCpx_XN"
      },
      "source": [
        "data.to_csv('preprocessed_seq',index=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A05hhCLwyMrv"
      },
      "source": [
        "data2=pd.read_csv('preprocessed_seq')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za1AkanJ-uKa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data2, test_size=0.2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nZenBqVPyiuj",
        "outputId": "5ffbcd01-0b50-4baf-87a4-1c27e10f4370"
      },
      "source": [
        "print(train.shape, validation.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(282230, 3) (70558, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlpK1NkZ-vHb"
      },
      "source": [
        "\n",
        "# for one sentence I will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this I can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
        "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "u0HvbffU-wxl",
        "outputId": "1c0f4a64-2572-43f7-9686-6fcaa1e22d22"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-96b82e9e-f2e1-4f3d-b90b-6f52f36e987d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51527</th>\n",
              "      <td>lei ha una foto</td>\n",
              "      <td>&lt;start&gt; she has a picture &lt;end&gt;</td>\n",
              "      <td>she has a picture &lt;end&gt; &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148404</th>\n",
              "      <td>ti sei divertita stasera</td>\n",
              "      <td>&lt;start&gt; did you have fun tonight</td>\n",
              "      <td>did you have fun tonight &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160795</th>\n",
              "      <td>abbiamo finito lo zucchero</td>\n",
              "      <td>&lt;start&gt; we have run out of sugar</td>\n",
              "      <td>we have run out of sugar &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328671</th>\n",
              "      <td>sembra carina a prescindere da quello che indossa</td>\n",
              "      <td>&lt;start&gt; she looks pretty no matter what she wears</td>\n",
              "      <td>she looks pretty no matter what she wears &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88315</th>\n",
              "      <td>come siamo venuti qui</td>\n",
              "      <td>&lt;start&gt; how did we come here</td>\n",
              "      <td>how did we come here &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302079</th>\n",
              "      <td>ha detto di essere già stato alle hawaii</td>\n",
              "      <td>&lt;start&gt; he said he had been to hawaii before</td>\n",
              "      <td>he said he had been to hawaii before &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216487</th>\n",
              "      <td>io pensavo che tom fosse canadese</td>\n",
              "      <td>&lt;start&gt; i thought tom was a canadian</td>\n",
              "      <td>i thought tom was a canadian &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74486</th>\n",
              "      <td>non ho una moglie</td>\n",
              "      <td>&lt;start&gt; i do not have a wife</td>\n",
              "      <td>i do not have a wife &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180345</th>\n",
              "      <td>sai chi vive qui</td>\n",
              "      <td>&lt;start&gt; do you know who lives here</td>\n",
              "      <td>do you know who lives here &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279779</th>\n",
              "      <td>preferirei essere qui che a boston</td>\n",
              "      <td>&lt;start&gt; i would rather be here than in boston</td>\n",
              "      <td>i would rather be here than in boston &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96b82e9e-f2e1-4f3d-b90b-6f52f36e987d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96b82e9e-f2e1-4f3d-b90b-6f52f36e987d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96b82e9e-f2e1-4f3d-b90b-6f52f36e987d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  italian  ...                                      english_out\n",
              "51527                                     lei ha una foto  ...                    she has a picture <end> <end>\n",
              "148404                           ti sei divertita stasera  ...                   did you have fun tonight <end>\n",
              "160795                         abbiamo finito lo zucchero  ...                   we have run out of sugar <end>\n",
              "328671  sembra carina a prescindere da quello che indossa  ...  she looks pretty no matter what she wears <end>\n",
              "88315                               come siamo venuti qui  ...                       how did we come here <end>\n",
              "302079           ha detto di essere già stato alle hawaii  ...       he said he had been to hawaii before <end>\n",
              "216487                  io pensavo che tom fosse canadese  ...               i thought tom was a canadian <end>\n",
              "74486                                   non ho una moglie  ...                       i do not have a wife <end>\n",
              "180345                                   sai chi vive qui  ...                 do you know who lives here <end>\n",
              "279779                 preferirei essere qui che a boston  ...      i would rather be here than in boston <end>\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "sjAkOfFf-y85",
        "outputId": "0691275e-5bc2-42cc-bc0b-859dfd4599e9"
      },
      "source": [
        "ita_lengths = train['italian'].str.split().apply(len)\n",
        "eng_lengths = train['english_inp'].str.split().apply(len)\n",
        "import seaborn as sns\n",
        "sns.kdeplot(ita_lengths)\n",
        "plt.show()\n",
        "sns.kdeplot(eng_lengths)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T7ehBs--p_T"
      },
      "source": [
        "tknizer_ita = Tokenizer()\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Vac5X91s-sJr",
        "outputId": "73d63a46-c885-4b97-9727-497e41cbbb5e"
      },
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(vocab_size_ita)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13121\n",
            "26649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b_cpMsdh-4a2",
        "outputId": "89b902f1-c231-425b-cd85-6c48d8187789"
      },
      "source": [
        "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10365)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Oe0mPE-Lrk"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
        "for word, i in tknizer_eng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-sB5uEE-IMV"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, enc_vocab_size, embedding_dim, enc_lstm_size, input_length):\n",
        "        super().__init__()\n",
        "        self.enc_vocab_size = enc_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.encoder_output=0\n",
        "        self.lstm_size=enc_lstm_size\n",
        "        self.lstm_output = 0\n",
        "        self.enc_state_h=0\n",
        "        self.enc_state_c=0\n",
        "      \n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.embedding = Embedding(input_dim=self.enc_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    def call(self, input_sentances, training=True):\n",
        "        input_embedd= self.embedding(input_sentances)\n",
        "        self.encoder_output, self.enc_state_h,self.enc_state_c = self.lstm(input_embedd)\n",
        "        return self.encoder_output, self.enc_state_h,self.enc_state_c\n",
        "\n",
        "    def initialize_states(self, batch_size):\n",
        "\n",
        "        lstm_h=tf.zeros(shape=[batch_size,self.lstm_size])\n",
        "        lstm_c=tf.zeros(shape=[batch_size,self.lstm_size])\n",
        "\n",
        "        return [lstm_h,lstm_c]\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ziSqOgmhLOe1",
        "outputId": "9177592c-9213-40b3-e2cf-5b0ae88716bc"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6fNro7E_5sD"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, dec_vocab_size, embedding_dim, dec_lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = dec_vocab_size\n",
        "        self.embedding_dim = 100\n",
        "        #self.dec_units = dec_units\n",
        "        self.lstm_size=dec_lstm_size\n",
        "        self.input_length = input_length\n",
        "        # we are using embedding_matrix and not training the embedding layer\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
        "    \n",
        "    def call(self, target_sentances, initial_state):\n",
        "        target_embedd = self.embedding(target_sentances)\n",
        "        decoder_output,lstm_h,lstm_c = self.lstm(target_embedd, initial_state)\n",
        "        return decoder_output,lstm_h,lstm_c"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kWhwgLNA_NW"
      },
      "source": [
        "# intial_hidden_state=np.zeros((batch_size,self.lstm_size))\n",
        "# intial_cell_state=np.zeros((batch_size,self.lstm_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0B0gokgKLOe8",
        "outputId": "7ebd94f3-fbec-4c60-92ca-d6b4821846c3"
      },
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXrIj4scLOe_"
      },
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, enc_inputs_len,dec_inputs_len, ed_vocab_size,batch_size):\n",
        "        \n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc=Encoder(enc_vocab_size=vocab_size_ita+1,embedding_dim=50,enc_lstm_size=256,input_length=enc_inputs_len)\n",
        "        self.dec=Decoder(dec_vocab_size=vocab_size_eng+1,embedding_dim=100,dec_lstm_size=256,input_length=dec_inputs_len)\n",
        "        self.dense_ed=Dense(ed_vocab_size, activation='softmax')\n",
        "        self.enc_states=self.enc.initialize_states(batch_size)\n",
        "    \n",
        "    \n",
        "    def call(self,input_ed):\n",
        "\n",
        "      data_enc=input_ed[0]\n",
        "      data_dec=input_ed[1]\n",
        "      encoder_output,final_state_h,final_state_c=self.enc(data_enc,self.enc_states)\n",
        "      decoder_output,state_h,state_c=self.dec(data_dec,[final_state_h,final_state_c])\n",
        "      dense_ed=self.dense_ed(decoder_output)\n",
        "\n",
        "      return dense_ed\n",
        "        "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGCD58nB-eCU"
      },
      "source": [
        "class Data_en:\n",
        "    def __init__(self, data2, tknizer_ita, tknizer_eng, len_data):\n",
        "        self.in_encoder = data2['italian'].values\n",
        "        self.in_decoder = data2['english_inp'].values\n",
        "        self.out_decoder = data2['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.len_data = len_data\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.in_encoder[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.in_decoder[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.out_decoder[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.in_encoder)\n",
        "\n",
        "    \n",
        "class LoadData(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, data_lan, batch_size=1):\n",
        "        self.data_lan = data_lan\n",
        "        self.batch_size = batch_size\n",
        "        self.index_data = np.arange(len(self.data_lan.in_encoder))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        a = i * self.batch_size\n",
        "        b = (i + 1) * self.batch_size\n",
        "        data_val = []\n",
        "        for j in range(a, b):\n",
        "            data_val.append(self.data_lan[j])\n",
        "\n",
        "        batch_data = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data_val)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch_data[0],batch_data[1]],batch_data[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.index_data) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.index_data = np.random.permutation(self.index_data)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vFlvl8On-gEk",
        "outputId": "2ab10381-3858-4e08-b683-e6c946dbe046"
      },
      "source": [
        "train_enc1 = Data_en(train, tknizer_ita, tknizer_eng, 20)\n",
        "test_ecn1  = Data_en(validation, tknizer_ita, tknizer_eng, 20)\n",
        "\n",
        "train_load = LoadData(train_enc1, batch_size=1024)\n",
        "test_load = LoadData(test_ecn1, batch_size=1024)\n",
        "\n",
        "\n",
        "print(train_load[0][0][0].shape, train_load[0][0][1].shape, train_load[0][1].shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024, 20) (1024, 20) (1024, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOPM-5-KJVbE",
        "outputId": "671f222f-5a6f-4553-c7e9-2fca6c78adce"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "logdir1 = os.path.join(\"logs1\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback1= tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)\n",
        "\n",
        "model1=Encoder_decoder(enc_inputs_len=20,dec_inputs_len=20,ed_vocab_size=vocab_size_eng,batch_size=1024)\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
        "train_steps1=train.shape[0]//1024\n",
        "valid_steps1=validation.shape[0]//1024\n",
        "model1.fit(train_load, steps_per_epoch=train_steps1, epochs=35, validation_data=train_load, validation_steps=valid_steps1,callbacks=[tensorboard_callback1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "274/274 [==============================] - 88s 295ms/step - loss: 1.8474 - val_loss: 1.6069\n",
            "Epoch 2/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 1.4759 - val_loss: 1.3590\n",
            "Epoch 3/35\n",
            "274/274 [==============================] - 71s 258ms/step - loss: 1.2951 - val_loss: 1.2232\n",
            "Epoch 4/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 1.1606 - val_loss: 1.0843\n",
            "Epoch 5/35\n",
            "274/274 [==============================] - 72s 263ms/step - loss: 1.0302 - val_loss: 0.9641\n",
            "Epoch 6/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.9232 - val_loss: 0.8679\n",
            "Epoch 7/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.8336 - val_loss: 0.7833\n",
            "Epoch 8/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.7548 - val_loss: 0.7082\n",
            "Epoch 9/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.6850 - val_loss: 0.6437\n",
            "Epoch 10/35\n",
            "274/274 [==============================] - 72s 261ms/step - loss: 0.6234 - val_loss: 0.5839\n",
            "Epoch 11/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.5681 - val_loss: 0.5316\n",
            "Epoch 12/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.5192 - val_loss: 0.4848\n",
            "Epoch 13/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.4747 - val_loss: 0.4442\n",
            "Epoch 14/35\n",
            "274/274 [==============================] - 72s 262ms/step - loss: 0.4353 - val_loss: 0.4045\n",
            "Epoch 15/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.4000 - val_loss: 0.3722\n",
            "Epoch 16/35\n",
            "274/274 [==============================] - 72s 261ms/step - loss: 0.3689 - val_loss: 0.3453\n",
            "Epoch 17/35\n",
            "274/274 [==============================] - 71s 258ms/step - loss: 0.3408 - val_loss: 0.3170\n",
            "Epoch 18/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.3161 - val_loss: 0.2933\n",
            "Epoch 19/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.2938 - val_loss: 0.2752\n",
            "Epoch 20/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.2740 - val_loss: 0.2551\n",
            "Epoch 21/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.2560 - val_loss: 0.2399\n",
            "Epoch 22/35\n",
            "274/274 [==============================] - 72s 263ms/step - loss: 0.2398 - val_loss: 0.2227\n",
            "Epoch 23/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.2253 - val_loss: 0.2090\n",
            "Epoch 24/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.2118 - val_loss: 0.1983\n",
            "Epoch 25/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.2002 - val_loss: 0.1870\n",
            "Epoch 26/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.1894 - val_loss: 0.1768\n",
            "Epoch 27/35\n",
            "274/274 [==============================] - 72s 262ms/step - loss: 0.1792 - val_loss: 0.1670\n",
            "Epoch 28/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.1700 - val_loss: 0.1576\n",
            "Epoch 29/35\n",
            "274/274 [==============================] - 72s 262ms/step - loss: 0.1617 - val_loss: 0.1496\n",
            "Epoch 30/35\n",
            "274/274 [==============================] - 71s 259ms/step - loss: 0.1538 - val_loss: 0.1436\n",
            "Epoch 31/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.1470 - val_loss: 0.1363\n",
            "Epoch 32/35\n",
            "274/274 [==============================] - 72s 262ms/step - loss: 0.1402 - val_loss: 0.1311\n",
            "Epoch 33/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.1339 - val_loss: 0.1253\n",
            "Epoch 34/35\n",
            "274/274 [==============================] - 71s 260ms/step - loss: 0.1279 - val_loss: 0.1197\n",
            "Epoch 35/35\n",
            "274/274 [==============================] - 82s 298ms/step - loss: 0.1225 - val_loss: 0.1144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22bb973990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnQcAMhrpDj2",
        "outputId": "eda5bd2f-503b-4264-f401-cb0e6cdd3220"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_1 (Encoder)          multiple                  1643268   \n",
            "_________________________________________________________________\n",
            "decoder_1 (Decoder)          multiple                  1673368   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  3360789   \n",
            "=================================================================\n",
            "Total params: 6,677,425\n",
            "Trainable params: 6,677,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ0Xio6wpGVL"
      },
      "source": [
        "model1.save_weights('encoder_decoder_task1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKJP9CkHthjF"
      },
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "  in_enc_ita=tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  in_pad_seq_ita=pad_sequences(in_enc_ita,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
        "  embed_pred=model1.layers[0].embedding(in_pad_seq_ita)\n",
        "  enc_ouput1,enc_state_h1,enc_state_c1=model1.layers[0].lstm(embed_pred)\n",
        "  in_indexs_2d=tknizer_eng.word_index['<start>']\n",
        "  in_indexs_2d=np.reshape(in_indexs_2d,(1,1))\n",
        "  att=np.zeros((20,20))\n",
        "  input_list=[]\n",
        "  for j in range(20):\n",
        "    out_pred,dec_state_h1,dec_state_c1=model1.layers[1](in_indexs_2d,[enc_state_h1,enc_state_c1])\n",
        "    dense_out1=model1.layers[2](out_pred)\n",
        "    enc_state_h1=dec_state_h1\n",
        "    enc_state_c1=dec_state_c1\n",
        "    out_index=np.argmax(dense_out1)\n",
        "    in_indexs_2d=np.reshape(out_index,(1,1))\n",
        "    input_list.append(tknizer_eng.index_word[out_index])\n",
        "    if tknizer_eng.index_word[out_index]=='<end>':\n",
        "      break\n",
        "  return ' '.join(input_list)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "996pFO8BLOfG"
      },
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP3A7cr3_OCd",
        "outputId": "9cf74cba-bff5-44e0-d893-b68b1e8a2765"
      },
      "source": [
        "ita=validation['italian'].values[:1000]\n",
        "eng=validation['english_out'].values[:1000]\n",
        "blue=[]\n",
        "for i in range(1000):\n",
        "  pred_bl=predict(ita[i])\n",
        "  blue.append(bleu_score.sentence_bleu(eng[i],pred_bl))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0xt6Oi2_WCK",
        "outputId": "f1cf4a09-085e-426d-aa3b-12df27debad3"
      },
      "source": [
        "print(f'Bleu_score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu_score: 0.8361471092114097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWFDxZXLOfJ"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdVfhBgmZoaf"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, enc_vocab_size, embedding_dim, enc_lstm_size, input_length):\n",
        "        super().__init__()\n",
        "        self.enc_vocab_size = enc_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.encoder_output=0\n",
        "        self.lstm_size=enc_lstm_size\n",
        "        self.lstm_output = 0\n",
        "        self.enc_state_h=0\n",
        "        self.enc_state_c=0\n",
        "      \n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.embedding = Embedding(input_dim=self.enc_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    def call(self, input_sentances, training=True):\n",
        "        input_embedd= self.embedding(input_sentances)\n",
        "        self.encoder_output, self.enc_state_h,self.enc_state_c = self.lstm(input_embedd)\n",
        "        return self.encoder_output, self.enc_state_h,self.enc_state_c\n",
        "\n",
        "    def initialize_states(self, batch_size):\n",
        "\n",
        "        lstm_h=tf.zeros(shape=[batch_size,self.lstm_size])\n",
        "        lstm_c=tf.zeros(shape=[batch_size,self.lstm_size])\n",
        "\n",
        "        return [lstm_h,lstm_c]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wRoe65b9LB0D",
        "outputId": "e4e8b881-da93-4c48-aa18-03ebccd7691f"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFoDGWQLxE81"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super().__init__()\n",
        "    self.scoring_function=scoring_function\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      self.att_units=att_units\n",
        "      self.softmax1=tf.keras.layers.Softmax(axis=1)\n",
        "    if scoring_function == 'general':\n",
        "      # Intialize variables needed for General score function here\n",
        "      # Initializing the weights\n",
        "      self.dense1=tf.keras.layers.Dense(self.att_units)\n",
        "      self.softmax1=tf.keras.layers.Softmax(axis=1)\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "      self.dense2=tf.keras.layers.Dense(self.att_units,activation='tanh')\n",
        "      self.dense_att=tf.keras.layers.Dense(1)\n",
        "      self.softmax1=tf.keras.layers.Softmax(axis=1)\n",
        "  \n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "    if self.scoring_function == 'dot':\n",
        "        \n",
        "        # Implement Dot score function here\n",
        "        d1=tf.keras.layers.Dot(axes=(2,1))([encoder_output,tf.reshape(decoder_hidden_state,\n",
        "                                                  [decoder_hidden_state.shape[0],decoder_hidden_state.shape[1],1])])\n",
        "        d1_softmax=self.softmax1(d1)\n",
        "        \n",
        "        \n",
        "        #Find the context vector\n",
        "        d2=tf.keras.layers.Dot(axes=(1,2))([d1_softmax,\n",
        "                                                  tf.reshape(encoder_output,shape=[encoder_output.shape[0],encoder_output.shape[2],encoder_output.shape[1]])])\n",
        "        dt_dot=tf.reshape(d2,shape=[d2.shape[0],d2.shape[2]])\n",
        "        return dt_dot,d1_softmax\n",
        "\n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        d1=self.dense1(decoder_hidden_state)\n",
        "        dt3=tf.reshape(d1,[d1.shape[0],d1.shape[1],1])\n",
        "        dt_general=tf.keras.layers.Dot(axes=(2,1))([encoder_output,dt3])\n",
        "        weights_general=self.softmax1(tf.cast(dt_general,dtype='float32'))\n",
        "        \n",
        "\n",
        "        # Find the context vector\n",
        "        d2=tf.keras.layers.Dot(axes=(1,2))([weights_general,tf.reshape(encoder_output,shape=[encoder_output.shape[0],encoder_output.shape[2],encoder_output.shape[1]])])\n",
        "        vector_general=tf.reshape(d2,shape=[d2.shape[0],d2.shape[2]])\n",
        "        return vector_general,weights_general\n",
        "\n",
        "                                                                             \n",
        "\n",
        "    elif self.scoring_function == 'concat':\n",
        "        \n",
        "        # Implementing concat function\n",
        "        dense_concat=self.dense_att(self.dense2(encoder_output)+tf.expand_dims(self.dense2(decoder_hidden_state),1))\n",
        "        softmax_concat=self.softmax1(tf.cast(dense_concat,dtype='float32'))#Finding the attention weight\n",
        "\n",
        "        #Finding the context vector\n",
        "\n",
        "        d2=tf.keras.layers.Dot(axes=(1,2))([softmax_concat,\n",
        "                                                  tf.reshape(encoder_output,shape=[encoder_output.shape[0],encoder_output.shape[2],encoder_output.shape[1]])])\n",
        "        vector_concat=tf.reshape(d2,shape=[d2.shape[0],d2.shape[2]])\n",
        "        return vector_concat,softmax_concat\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51x50h_TLrl9",
        "outputId": "2e472142-ec90-4499-f0d8-6382062dce84"
      },
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8QqGj6MnO90"
      },
      "source": [
        "class OneStepDecoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      super().__init__()\n",
        "\n",
        "      self.tar_vocab_size=tar_vocab_size\n",
        "      self.embedding_dim=embedding_dim\n",
        "      self.input_length=input_length\n",
        "      self.dec_units=dec_units\n",
        "      self.score_fun=score_fun\n",
        "      self.att_units=att_units\n",
        "\n",
        "      self.embed_osd=Embedding(input_dim = self.tar_vocab_size, output_dim = self.embedding_dim,\n",
        "                                      input_length = self.input_length, name=\"embedding_layer_osd\")\n",
        "      self.lst_osd= LSTM(self.dec_units, return_sequences=True,return_state=True,name=\"osd_LSTM\")\n",
        "       \n",
        "      self.att_osd = Attention(self.score_fun,self.att_units)\n",
        "\n",
        "      self.dense_osd = Dense(self.tar_vocab_size)\n",
        "    \n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "\n",
        "    vec_osd,wgt=self.att_osd(state_h,encoder_output)\n",
        "    embed_target=self.embed_osd(input_to_decoder)\n",
        "    t=tf.expand_dims(vec_osd,1)\n",
        "    cnct=tf.concat([embed_target,t],axis=2)\n",
        "    output_osd,hid_osd,cell_osd=self.lst_osd(cnct)\n",
        "    output_osd=tf.reshape(output_osd,(-1,output_osd.shape[2]))\n",
        "    output_osd=self.dense_osd(output_osd)\n",
        "    return output_osd,hid_osd,cell_osd,wgt,vec_osd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLEXhChnMC1k",
        "outputId": "32a48db4-6f79-4846-fbc5-946761426261"
      },
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=OneStepDecoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syrQHkPtq0bs"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.out_vocab_size=out_vocab_size\n",
        "      self.embedding_dim= embedding_dim\n",
        "      self.input_length =input_length\n",
        "      self.dec_units=dec_units\n",
        "      self.score_fun=score_fun\n",
        "      self.att_units=att_units\n",
        "      self.onestep_decoder = OneStepDecoder(self.out_vocab_size,self.embedding_dim,self.input_length,self.dec_units, self.score_fun,self.att_units)\n",
        "    \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "      var=tf.TensorArray(tf.float32,size=len(input_to_decoder[0]),name='tensor_deocoder')\n",
        "      for i in range(len(input_to_decoder[0])):\n",
        "        out1,hid_dec,cell_dec,wgt_dec,cnv_vec=self.onestep_decoder(input_to_decoder[:,i:i+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n",
        "        var=var.write(i,out1)\n",
        "      var=tf.transpose(var.stack(),[1,0,2])\n",
        "      return var"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtbx6onFMJXb",
        "outputId": "2ec7beb9-9d26-4d49-8f80-f4c938fd2dca"
      },
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jpfikYfZkaj"
      },
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, input_len,output_len, score_ecm,att_units,batch_size):\n",
        "        \n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "\n",
        "        super().__init__()\n",
        "        self.input_len=input_len\n",
        "        self.output_len=output_len\n",
        "        self.score_ecm=score_ecm\n",
        "        self.batch_size=batch_size\n",
        "        self.att_units=att_units\n",
        "        self.enc=Encoder(enc_vocab_size=vocab_size_ita+1,embedding_dim=50,input_length=input_len,enc_lstm_size=256)\n",
        "        self.dec=Decoder(out_vocab_size=vocab_size_eng+1,embedding_dim=100,dec_units=256,input_length=self.output_len,score_fun=self.score_ecm,att_units=self.att_units)\n",
        "        self.enc_state1,self.encoder_state2=self.enc.initialize_states(self.batch_size)\n",
        "    \n",
        "    \n",
        "    def call(self,input_ed):\n",
        "      enc_output,enc_hid,enc_cell=self.enc(input_ed[0],[self.enc_state1,self.encoder_state2])\n",
        "      decoder_output=self.dec(input_ed[1],enc_output,enc_hid,enc_cell)\n",
        "\n",
        "      return decoder_output\n",
        "        "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfZET6OSxou8"
      },
      "source": [
        "loss1= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "def custom_lossfunction(targets,logits):\n",
        "\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
        "  \n",
        "  target=tf.math.logical_not(tf.math.equal(targets,0))\n",
        "  loss2=loss1(targets,logits)\n",
        "  #masking loss for padding\n",
        "  \n",
        "  target=tf.cast(target,dtype=loss2.dtype)\n",
        "  loss2*=target\n",
        "\n",
        "  return tf.reduce_mean(loss2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QlbWAqNNlqe"
      },
      "source": [
        "<font color='blue'>**Training**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtZUQF2NuZE"
      },
      "source": [
        "Implement dot function here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnt1Xrluxz3i"
      },
      "source": [
        "class Data_en:\n",
        "    def __init__(self, data2, tknizer_ita, tknizer_eng, len_data):\n",
        "        self.in_encoder = data2['italian'].values\n",
        "        self.in_decoder = data2['english_inp'].values\n",
        "        self.out_decoder = data2['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.len_data = len_data\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.in_encoder[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.in_decoder[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.out_decoder[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.len_data, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.in_encoder)\n",
        "\n",
        "    \n",
        "class LoadData(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, data_lan, batch_size=1):\n",
        "        self.data_lan = data_lan\n",
        "        self.batch_size = batch_size\n",
        "        self.index_data = np.arange(len(self.data_lan.in_encoder))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        a = i * self.batch_size\n",
        "        b = (i + 1) * self.batch_size\n",
        "        data_val = []\n",
        "        for j in range(a, b):\n",
        "            data_val.append(self.data_lan[j])\n",
        "\n",
        "        batch_data = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data_val)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch_data[0],batch_data[1]],batch_data[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.index_data) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.index_data = np.random.permutation(self.index_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHejgRtSx6uB",
        "outputId": "73e7dd1a-a0e7-49df-c6f4-6b9512f77a37"
      },
      "source": [
        "train_enc1 = Data_en(train, tknizer_ita, tknizer_eng, 20)\n",
        "test_ecn1  = Data_en(validation, tknizer_ita, tknizer_eng, 20)\n",
        "\n",
        "train_load = LoadData(train_enc1, batch_size=1024)\n",
        "test_load = LoadData(test_ecn1, batch_size=1024)\n",
        "\n",
        "\n",
        "print(train_load[0][0][0].shape, train_load[0][0][1].shape, train_load[0][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1024, 20) (1024, 20) (1024, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvSu7Cgep761"
      },
      "source": [
        "tf.config.run_functions_eagerly(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bzlbIavhs0F",
        "outputId": "b8d7d64e-5f5c-4010-c1ef-dacf66ad371b"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ-InzoIyBfP"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "logdir2 = os.path.join(\"logs2\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback2= tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVWZraF9tzVK"
      },
      "source": [
        "model2 = encoder_decoder(input_len=20,output_len=20,score_ecm='dot',att_units=64,batch_size=1024)\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
        "train_steps2=train.shape[0]//1024\n",
        "valid_steps2=validation.shape[0]//1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BqHntxXomk2",
        "outputId": "1fe42c45-b96c-4ea2-fd37-058e344d9a2d"
      },
      "source": [
        "model2.fit(train_load, steps_per_epoch=train_steps2, epochs=20, validation_data=train_load, validation_steps=valid_steps2,callbacks=[tensorboard_callback2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "274/274 [==============================] - 180s 634ms/step - loss: 2.2795 - val_loss: 2.2086\n",
            "Epoch 2/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 2.0567 - val_loss: 2.0998\n",
            "Epoch 3/20\n",
            "274/274 [==============================] - 168s 615ms/step - loss: 1.9903 - val_loss: 2.1099\n",
            "Epoch 4/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 1.9337 - val_loss: 2.1169\n",
            "Epoch 5/20\n",
            "274/274 [==============================] - 170s 620ms/step - loss: 1.9559 - val_loss: 2.1088\n",
            "Epoch 6/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 1.9167 - val_loss: 2.1478\n",
            "Epoch 7/20\n",
            "274/274 [==============================] - 169s 616ms/step - loss: 1.8669 - val_loss: 2.1071\n",
            "Epoch 8/20\n",
            "274/274 [==============================] - 169s 618ms/step - loss: 1.8785 - val_loss: 2.2818\n",
            "Epoch 9/20\n",
            "274/274 [==============================] - 169s 616ms/step - loss: 2.0188 - val_loss: 2.2763\n",
            "Epoch 10/20\n",
            "274/274 [==============================] - 169s 617ms/step - loss: 1.8769 - val_loss: 2.1157\n",
            "Epoch 11/20\n",
            "274/274 [==============================] - 169s 617ms/step - loss: 1.8726 - val_loss: 2.1139\n",
            "Epoch 12/20\n",
            "274/274 [==============================] - 162s 591ms/step - loss: 1.9173 - val_loss: 2.1381\n",
            "Epoch 13/20\n",
            "274/274 [==============================] - 169s 617ms/step - loss: 1.8898 - val_loss: 2.1971\n",
            "Epoch 14/20\n",
            "274/274 [==============================] - 169s 615ms/step - loss: 1.8776 - val_loss: 2.1445\n",
            "Epoch 15/20\n",
            "274/274 [==============================] - 160s 584ms/step - loss: 1.8333 - val_loss: 2.1426\n",
            "Epoch 16/20\n",
            "274/274 [==============================] - 161s 587ms/step - loss: 1.8258 - val_loss: 2.2093\n",
            "Epoch 17/20\n",
            "274/274 [==============================] - 159s 580ms/step - loss: 1.8800 - val_loss: 2.1719\n",
            "Epoch 18/20\n",
            "274/274 [==============================] - 169s 618ms/step - loss: 1.9721 - val_loss: 2.2018\n",
            "Epoch 19/20\n",
            "274/274 [==============================] - 160s 584ms/step - loss: 1.8712 - val_loss: 2.1326\n",
            "Epoch 20/20\n",
            "274/274 [==============================] - 161s 585ms/step - loss: 1.9660 - val_loss: 2.1298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22ba618b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLxgpthTyDiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165e98cc-330a-43f2-d76e-41c4cfd39d9f"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_3 (Encoder)          multiple                  1643268   \n",
            "_________________________________________________________________\n",
            "decoder_5 (Decoder)          multiple                  5296558   \n",
            "=================================================================\n",
            "Total params: 6,939,826\n",
            "Trainable params: 6,939,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1tYMGQYyDap"
      },
      "source": [
        "model2.save_weights('seq_dot_model2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "## <font color='blue'>**Inference**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "<font color='blue'>**Plot attention weights**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ACiW1nryJB0"
      },
      "source": [
        "#Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention,act,pred):\n",
        "  \n",
        "  pred,_=predict(act,plot_t2='dot')\n",
        "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
        "  fig,ax = plt.subplots(figsize=(8,6))\n",
        "  ax.matshow(attention,cmap='Blues')\n",
        "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
        "  ax.set_yticklabels([''] + pred.split(' '))\n",
        "  plt.show() \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR3rkRujyQoQ"
      },
      "source": [
        "def predict(input_sentence,plot_t2):\n",
        "\n",
        "  sentences=[]\n",
        "  in_enc_ita=tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  in_pad_seq_ita=pad_sequences(in_enc_ita,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
        "  state_enc1=model2.layers[0].initialize_states(in_pad_seq_ita.shape[0])\n",
        "  enc_ouput1,enc_state_h1,enc_state_c1=model2.layers[0](in_pad_seq_ita,state_enc1)\n",
        "  in_indexs=tknizer_eng.word_index['<start>']\n",
        "  in_indexs=tf.expand_dims([in_indexs],0)\n",
        "  att=np.zeros((20,20))\n",
        "  input_list=[]\n",
        "  for j in range(in_pad_seq_ita.shape[1]):\n",
        "    out_pred,dec_state_h1,dec_state_c1,w,cv=model2.layers[1].onestep_decoder(in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    dense_out1=model2.layers[1](in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    out_index=np.argmax(dense_out1)\n",
        "    wt=tf.reshape(w,(-1, ))\n",
        "    att[j]=wt.numpy()\n",
        "    in_indexs=np.reshape(out_index,(1,1))\n",
        "    input_list.append(tknizer_eng.index_word[out_index])\n",
        "    if tknizer_eng.index_word[out_index]=='<end>':\n",
        "      break\n",
        "  return ' '.join(input_list),att\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usOCV-6Pkk5X"
      },
      "source": [
        "**ATTETNTION PLOTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "pQeh7GV2j6W_",
        "outputId": "a3a080c4-0cd6-4107-dc7f-4a50317ae48b"
      },
      "source": [
        "pred,attention=predict('1 2 3 4','dot')\n",
        "plot_attention(attention,'1 2 3 4',pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iHiLdROM23l"
      },
      "source": [
        "# #Create an object of your custom model.\n",
        "# #Compile and train your model on dot scoring function.\n",
        "# # Visualize few sentences randomly in Test data\n",
        "# # Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# # https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "# #Sample example\n",
        "# import nltk.translate.bleu_score as bleu\n",
        "# reference = ['i am groot'.split(),] # the original\n",
        "# translation = 'it is ship'.split() # trasilated using model\n",
        "# print('BLEU score: {}'.format(bleu.sentence_bleu(reference, translation)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZr7et_Eycbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607a3d48-1726-441c-cb0d-7d5bc34e9711"
      },
      "source": [
        "ita=validation['italian'].values[:1000]\n",
        "eng=validation['english_out'].values[:1000]\n",
        "blue=[]\n",
        "for i in range(1000):\n",
        "  pred_bl,att_bl=predict(ita[i],'dot')\n",
        "  blue.append(bleu_score.sentence_bleu(eng[i],pred_bl))\n",
        "print(f'Bleu_score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Bleu_score: 0.8246226835237551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvOcIxOHyhyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eba5a23-8d7d-4d2c-a093-707027f461c2"
      },
      "source": [
        "print(f'Bleu Score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu Score: 0.8246226835237551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWg2ferDQvT3"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rh9_w79M5JO"
      },
      "source": [
        "#Compile and train your model on general scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xf850agyw4V"
      },
      "source": [
        "logdir3 = os.path.join(\"logs3\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback3= tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKqBjrlOLNRn"
      },
      "source": [
        "model3 = encoder_decoder(input_len=20,output_len=20,score_ecm='general',att_units=64,batch_size=1024)\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
        "train_steps3=train.shape[0]//1024\n",
        "valid_steps3=validation.shape[0]//1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTrju7uJLUNx",
        "outputId": "83cbf78f-df76-41be-ace7-ef6926d55164"
      },
      "source": [
        "model3.fit(train_load, steps_per_epoch=train_steps3, epochs=20, validation_data=train_load, validation_steps=valid_steps3,callbacks=[tensorboard_callback3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "274/274 [==============================] - 170s 602ms/step - loss: 2.3031 - val_loss: 2.2873\n",
            "Epoch 2/20\n",
            "274/274 [==============================] - 161s 587ms/step - loss: 2.0556 - val_loss: 2.0834\n",
            "Epoch 3/20\n",
            "274/274 [==============================] - 169s 616ms/step - loss: 1.9527 - val_loss: 2.0697\n",
            "Epoch 4/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 1.9027 - val_loss: 2.0626\n",
            "Epoch 5/20\n",
            "274/274 [==============================] - 169s 618ms/step - loss: 1.8735 - val_loss: 2.0988\n",
            "Epoch 6/20\n",
            "274/274 [==============================] - 163s 593ms/step - loss: 1.9859 - val_loss: 2.0837\n",
            "Epoch 7/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 2.0781 - val_loss: 2.1448\n",
            "Epoch 8/20\n",
            "274/274 [==============================] - 169s 616ms/step - loss: 1.9704 - val_loss: 2.0715\n",
            "Epoch 9/20\n",
            "274/274 [==============================] - 169s 618ms/step - loss: 1.8394 - val_loss: 2.0547\n",
            "Epoch 10/20\n",
            "274/274 [==============================] - 172s 627ms/step - loss: 1.8451 - val_loss: 2.0558\n",
            "Epoch 11/20\n",
            "274/274 [==============================] - 162s 591ms/step - loss: 1.8470 - val_loss: 2.0613\n",
            "Epoch 12/20\n",
            "274/274 [==============================] - 161s 588ms/step - loss: 1.8629 - val_loss: 2.0650\n",
            "Epoch 13/20\n",
            "274/274 [==============================] - 162s 593ms/step - loss: 1.7991 - val_loss: 2.0666\n",
            "Epoch 14/20\n",
            "274/274 [==============================] - 171s 624ms/step - loss: 1.8351 - val_loss: 2.0584\n",
            "Epoch 15/20\n",
            "274/274 [==============================] - 162s 590ms/step - loss: 1.7662 - val_loss: 2.0611\n",
            "Epoch 16/20\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 1.7702 - val_loss: 2.0745\n",
            "Epoch 17/20\n",
            "274/274 [==============================] - 162s 590ms/step - loss: 1.8164 - val_loss: 2.1583\n",
            "Epoch 18/20\n",
            "274/274 [==============================] - 163s 593ms/step - loss: 1.7527 - val_loss: 2.0482\n",
            "Epoch 19/20\n",
            "274/274 [==============================] - 171s 623ms/step - loss: 1.7108 - val_loss: 2.1021\n",
            "Epoch 20/20\n",
            "274/274 [==============================] - 170s 620ms/step - loss: 1.7891 - val_loss: 2.0725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22ccba2c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgo0iw8uy1UJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ccbfd0e-93e9-483b-8643-519d5fa0f5db"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_4 (Encoder)          multiple                  1643268   \n",
            "_________________________________________________________________\n",
            "decoder_6 (Decoder)          multiple                  5296558   \n",
            "=================================================================\n",
            "Total params: 6,939,826\n",
            "Trainable params: 6,939,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ua_fmKWrrbw"
      },
      "source": [
        "%tensorboard --logdir logs3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GqDAETzy0x2"
      },
      "source": [
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention,act,pred):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "\n",
        "  pred,_=predict(act,plot_t2='general')\n",
        "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
        "  fig,ax = plt.subplots(figsize=(8,6))\n",
        "  ax.matshow(attention,cmap='Blues')\n",
        "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
        "  ax.set_yticklabels([''] + pred.split(' '))\n",
        "  plt.show() \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "-GW2mb4cYneK",
        "outputId": "c1651131-6d8c-4f60-8182-e10e872ac58c"
      },
      "source": [
        "pred,attention=predict('1 2 3 4','general')\n",
        "plot_attention(attention,'1 2 3 4',pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PxiQuDby41L"
      },
      "source": [
        "def predict(input_sentence,plot_t2):\n",
        "\n",
        "  sentences=[]\n",
        "  in_enc_ita=tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  in_pad_seq_ita=pad_sequences(in_enc_ita,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
        "  state_enc1=model3.layers[0].initialize_states(in_pad_seq_ita.shape[0])\n",
        "  enc_ouput1,enc_state_h1,enc_state_c1=model3.layers[0](in_pad_seq_ita,state_enc1)\n",
        "  in_indexs=tknizer_eng.word_index['<start>']\n",
        "  in_indexs=tf.expand_dims([in_indexs],0)\n",
        "  att=np.zeros((20,20))\n",
        "  input_list=[]\n",
        "  for j in range(in_pad_seq_ita.shape[1]):\n",
        "    out_pred,dec_state_h1,dec_state_c1,w,cv=model3.layers[1].onestep_decoder(in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    dense_out1=model3.layers[1](in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    out_index=np.argmax(dense_out1)\n",
        "    wt=tf.reshape(w,(-1, ))\n",
        "    att[j]=wt.numpy()\n",
        "    in_indexs=np.reshape(out_index,(1,1))\n",
        "    input_list.append(tknizer_eng.index_word[out_index])\n",
        "    if tknizer_eng.index_word[out_index]=='<end>':\n",
        "      break\n",
        "  return ' '.join(input_list),att\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJIATpUjkPji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbf360c-3512-4aae-c928-eb4e339d79a5"
      },
      "source": [
        "ita=validation['italian'].values[:1000]\n",
        "eng=validation['english_out'].values[:1000]\n",
        "blue=[]\n",
        "for i in range(1000):\n",
        "  pred_bl,att_bl=predict(ita[i],'general')\n",
        "  blue.append(bleu_score.sentence_bleu(eng[i],pred_bl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCROC9kSY6cr",
        "outputId": "6a9b6aad-1377-480b-9e8e-90d682ebc17f"
      },
      "source": [
        "print(f'Bleu_score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu_score: 0.8705149732218294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kN9ZWViQNMB"
      },
      "source": [
        "#Compile and train your model on concat scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NflanuazD-J"
      },
      "source": [
        "logdir4 = os.path.join(\"logs4\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback4= tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6C2dI4lZSB4"
      },
      "source": [
        "model4 = encoder_decoder(input_len=20,output_len=20,score_ecm='concat',att_units=64,batch_size=1024)\n",
        "model4.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy')\n",
        "train_steps3=train.shape[0]//1024\n",
        "valid_steps3=validation.shape[0]//1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7G4n0NUZVrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0c3e9c-a1c5-4c65-9712-a4c7dd623f04"
      },
      "source": [
        "model4.fit(train_load, steps_per_epoch=train_steps3, epochs=20, validation_data=train_load, validation_steps=valid_steps3,callbacks=[tensorboard_callback4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "274/274 [==============================] - 187s 659ms/step - loss: 2.3358 - val_loss: 2.2126\n",
            "Epoch 2/20\n",
            "274/274 [==============================] - 184s 671ms/step - loss: 1.9897 - val_loss: 2.1768\n",
            "Epoch 3/20\n",
            "274/274 [==============================] - 183s 669ms/step - loss: 1.9982 - val_loss: 2.0986\n",
            "Epoch 4/20\n",
            "274/274 [==============================] - 183s 669ms/step - loss: 1.9786 - val_loss: 2.1295\n",
            "Epoch 5/20\n",
            "274/274 [==============================] - 184s 672ms/step - loss: 1.8858 - val_loss: 2.1411\n",
            "Epoch 6/20\n",
            "274/274 [==============================] - 177s 647ms/step - loss: 1.8964 - val_loss: 2.1293\n",
            "Epoch 7/20\n",
            "274/274 [==============================] - 176s 644ms/step - loss: 1.9157 - val_loss: 2.0868\n",
            "Epoch 8/20\n",
            "274/274 [==============================] - 176s 644ms/step - loss: 1.9690 - val_loss: 2.0937\n",
            "Epoch 9/20\n",
            "274/274 [==============================] - 182s 664ms/step - loss: 1.8564 - val_loss: 2.0578\n",
            "Epoch 10/20\n",
            "274/274 [==============================] - 184s 672ms/step - loss: 1.8450 - val_loss: 2.0726\n",
            "Epoch 11/20\n",
            "274/274 [==============================] - 183s 669ms/step - loss: 1.9960 - val_loss: 2.1153\n",
            "Epoch 12/20\n",
            "274/274 [==============================] - 182s 666ms/step - loss: 1.9400 - val_loss: 2.2613\n",
            "Epoch 13/20\n",
            "274/274 [==============================] - 183s 666ms/step - loss: 1.8545 - val_loss: 2.0846\n",
            "Epoch 14/20\n",
            "274/274 [==============================] - 183s 667ms/step - loss: 1.9415 - val_loss: 2.1064\n",
            "Epoch 15/20\n",
            "274/274 [==============================] - 183s 666ms/step - loss: 1.8513 - val_loss: 2.0828\n",
            "Epoch 16/20\n",
            "274/274 [==============================] - 176s 642ms/step - loss: 1.8114 - val_loss: 2.0665\n",
            "Epoch 17/20\n",
            "274/274 [==============================] - 183s 668ms/step - loss: 1.7609 - val_loss: 2.0643\n",
            "Epoch 18/20\n",
            "274/274 [==============================] - 176s 643ms/step - loss: 1.8445 - val_loss: 2.1551\n",
            "Epoch 19/20\n",
            "274/274 [==============================] - 181s 661ms/step - loss: 1.9178 - val_loss: 2.1682\n",
            "Epoch 20/20\n",
            "274/274 [==============================] - 183s 667ms/step - loss: 1.8762 - val_loss: 2.1254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f225cbfa790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRbRL2K8zGxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eeb0bc4-3132-4f45-9989-59451c0ffb0d"
      },
      "source": [
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_decoder_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_5 (Encoder)          multiple                  1643268   \n",
            "_________________________________________________________________\n",
            "decoder_7 (Decoder)          multiple                  5329519   \n",
            "=================================================================\n",
            "Total params: 6,972,787\n",
            "Trainable params: 6,972,787\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogp300Z0zLW5"
      },
      "source": [
        "model4.save_weights('concat_model4.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l3J_rzbrw75"
      },
      "source": [
        "!kill 1690"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LRVqM68Z9Fz"
      },
      "source": [
        "def predict(input_sentence,plot_t2):\n",
        "\n",
        "  sentences=[]\n",
        "  in_enc_ita=tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  in_pad_seq_ita=pad_sequences(in_enc_ita,maxlen=20,padding='post',truncating='post',dtype='int32')\n",
        "  state_enc1=model4.layers[0].initialize_states(in_pad_seq_ita.shape[0])\n",
        "  enc_ouput1,enc_state_h1,enc_state_c1=model4.layers[0](in_pad_seq_ita,state_enc1)\n",
        "  in_indexs=tknizer_eng.word_index['<start>']\n",
        "  in_indexs=tf.expand_dims([in_indexs],0)\n",
        "  att=np.zeros((20,20))\n",
        "  input_list=[]\n",
        "  for j in range(in_pad_seq_ita.shape[1]):\n",
        "    out_pred,dec_state_h1,dec_state_c1,w,cv=model4.layers[1].onestep_decoder(in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    dense_out1=model4.layers[1](in_indexs,enc_ouput1,enc_state_h1,enc_state_c1)\n",
        "    out_index=np.argmax(dense_out1)\n",
        "    wt=tf.reshape(w,(-1, ))\n",
        "    att[j]=wt.numpy()\n",
        "    in_indexs=np.reshape(out_index,(1,1))\n",
        "    input_list.append(tknizer_eng.index_word[out_index])\n",
        "    if tknizer_eng.index_word[out_index]=='<end>':\n",
        "      break\n",
        "  return ' '.join(input_list),att\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8-4XDE5zKrh"
      },
      "source": [
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention,act,pred):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "\n",
        "  pred,_=predict(act,plot_t2='concat')\n",
        "  plot_att=attention[:len(pred.split(' ')),len(act.split(' '))]\n",
        "  fig,ax = plt.subplots(figsize=(8,6))\n",
        "  ax.matshow(attention,cmap='Blues')\n",
        "  ax.set_xticklabels([''] + act.split(' '), rotation=90)\n",
        "  ax.set_yticklabels([''] + pred.split(' '))\n",
        "  plt.show() \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLQlEDEGaI_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "21c843a9-f7a5-49b8-e3b2-c68f1a6cf61d"
      },
      "source": [
        "pred,attention=predict('1 2 3 4','concat')\n",
        "plot_attention(attention,'1 2 3 4',pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbmmEMtazNyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da81fa6-32ca-4580-d0c2-726e8030ae78"
      },
      "source": [
        "ita=validation['italian'].values[:1000]\n",
        "eng=validation['english_out'].values[:1000]\n",
        "blue=[]\n",
        "for i in range(1000):\n",
        "  pred_bl,att_bl=predict(ita[i],'concat')\n",
        "  blue.append(bleu_score.sentence_bleu(eng[i],pred_bl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3JaPGSFZvZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0ef35e-b0d2-4355-ae84-efc2274200ae"
      },
      "source": [
        "print(f'Bleu_score: {np.average(blue)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu_score: 0.5097968335141377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff1lV0ITM6_p"
      },
      "source": [
        "# Write your observations on each of the scoring function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLo30Q7Istma"
      },
      "source": [
        "**OBSERVATIONS OF ATTENTION MECHANISM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cAybyE8LtS7R",
        "outputId": "048fcff5-ebd8-451b-cc0e-a71710b1b4b4"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "x = PrettyTable()\n",
        "x.field_names = [\"No\",\"Scoring Function\", \"Bleu Score\"]\n",
        "\n",
        "x.add_row([\"1\",\"Dot\",0.8325 ])\n",
        "x.add_row([\"2\",\"General\", 0.8614])\n",
        "x.add_row([\"3\",\"Concat \", 0.510])\n",
        "print(x)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------+------------+\n",
            "| No | Scoring Function | Bleu Score |\n",
            "+----+------------------+------------+\n",
            "| 1  |       Dot        |   0.8325   |\n",
            "| 2  |     General      |   0.8614   |\n",
            "| 3  |     Concat       |    0.51    |\n",
            "+----+------------------+------------+\n"
          ]
        }
      ]
    }
  ]
}